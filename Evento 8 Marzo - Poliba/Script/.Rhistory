install.packages("textstem")
install.packages("NLP")
install.packages("ggraph")
install.packages("ggraph")
install.packages("devtools")
install.packages("tidyverse")
install.packages("textstem")
#install.packages("reshape2")
install.packages("igraph")
install.packages("reshape2")
#### 1.1 IMPORT LIBRARY
#funzione per caricare i pacchetti library() - da caricare in memoria ad ogni accesso in RStudio
?devtools
#### 1.1 IMPORT LIBRARY
#funzione per caricare i pacchetti library() - da caricare in memoria ad ogni accesso in RStudio
??devtools
#### 1.1 IMPORT LIBRARY
#funzione per caricare i pacchetti library() - da caricare in memoria ad ogni accesso in RStudio
??igraph
library(devtools)  #caricamento pacchetti da repository non ufficiali (es. CRAN)
library(tidyverse) #manipolazione dei dati
library(tidytext)  #ordinare i testi
library(textstem)  #Strumenti per Stemming e Lemmatizzare il testo
#library(reshape2)
library(igraph)    #grafici network
library(ggraph)    #grafici grafi e network
library(quanteda)  #quantitative analysis for textual data
library(NLP)       #natural language processing
#### 1.2 INSTALL FROM GITHUB HARRY POTTER LIBRARY
devtools::install_github("bradleyboehmke/harrypotter")
library(harrypotter)
corpus <- corpus(philosophers_stone)
View(corpus)
tokens<-quanteda::tokens(corpus,"word",  remove_numbers = T, remove_punct = T,
remove_symbols = T, remove_separators = TRUE,
remove_twitter = T, remove_hyphens = T, remove_url = T,
ngrams = 1L, skip = 0L, concatenator = "_",
verbose = quanteda_options("verbose"), include_docvars = TRUE)%>%
tokens_remove(stop_words$word)
tokens$text1[1:30]
tokens <- lemmatize_strings(tokens, dictionary = lexicon::hash_lemmas)
dfm <- dfm(tokens)
color <- c("darkorchid4","magenta3","darkorchid","magenta4")
textplot_wordcloud(dfm,max.words = 120,rotation = 0.3,min_size = 1.3, max_size = 9,colors=color,labelsize = 8)
#4.1 REMOVE WORD 'HARRY' from TOKENS
tokens <- gsub("Harry","",tokens)
dfm2 <- dfm(tokens)
#5 CLEANED WORDCLOUD
textplot_wordcloud(dfm2,max.words = 100,rotation = 0.3,min_size =1.3, max_size = 9,colors=color,labelsize = 8)
lemma_translator <- function(MyLemma){
MyTextList <- as.character(gsub("\n", " ",paste(unlist(as.String(MyLemma)))))
return(MyTextList)
}
text <- data.frame(text=lemma_translator(tokens))
n_gram <- text %>%
unnest_tokens(ngram, text, token = "ngrams", n = 2)
bigram <- data.frame(ngram=n_gram[,"ngram"])
bigram_sep <- bigram %>%
separate(ngram, c("word1", "word2"), sep = " ")
bigram_counts <- bigram_sep %>%
dplyr::count(word1, word2, sort = TRUE)
bigram_counts <- bigram_counts[!is.na(bigram_counts$word1)|!is.na(bigram_counts$word2),]
bigram_graph <- bigram_counts %>%
filter(n >= 10) %>%
graph_from_data_frame()
bigram_graph
set.seed(9999)
ggraph(bigram_graph, layout = "igraph",algorithm = "nicely") +
geom_edge_link(edge_colour="magenta4",aes(edge_alpha = n, edge_width = n)) +
geom_node_point(color = "magenta3", size = 2) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void() +
theme(plot.margin =margin(t = 20, r =20, b = 20, l = 20, unit = "pt"))
